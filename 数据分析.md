## 3. ANN

### 3.1 ANN

- 定义：由大量具有适应性的处理元素（神经元（***阈值、单向传递、延时***））组成的广泛并行互联网络

- 树突（输入）轴突（输出、神经纤维）
- 突触（信息传递）
  - 突出前：第一个神经元轴突末梢
  - 突出后：第二个神经元树突或细胞体等受体表面

- 信息产生（细胞膜对不同离子不同通透性，造成膜内外离子浓度差）
  - 无信号，极化状态，静息电位（-70mv），内负外正
  - 兴奋，去极化，静息电位正向偏移
  - 抑制，超极化，负向偏移

- 兴奋产生 
  - 超过阈值（-55mv），膜电位极速升高（+30mv），后极速下降回到静息电位
  - 产生一个电脉冲兴奋后，会有***暂时性阈值上升***，持续1ms后下降到正常水平，这段时间即使有刺激也不会产生兴奋，***不应期***
  - 神经元电脉冲宽度幅度***相同***，刺激越强，脉冲频率越高
- 兴奋传递
  - 突触前的突触小泡产生并释放***递质***，扩散后与突触后的受体结合，受体性质决定***兴奋抑制***
  - 兴奋性突触，膜电位随递质和受体结合数量上升而上升，电位向正向移动产生电脉冲
  - 化学角度看，是膜对***离子通透性***改变

- 信息整合
  - 空间整合，同一时刻的输入刺激产生的膜电位变化，等于单独刺激引起变化综合
  - 时间整合，输入脉冲到达神经元时间不同

<img src="C:\Users\xn666\AppData\Roaming\Typora\typora-user-images\image-20230614141448140.png" alt="image-20230614141448140" style="zoom:50%;" />

- 激活函数
  - 作用：进行非线性变换，增强系统非线性表达能力
  - 描述  ***激活状态和输出*** 关系

- 分类：分层型（前向、反馈）；相互连接型
- ANN基本属性：非线性、无限制性、非定常性、非凸性

### 3.2 ANN学习

#### 1、学习方法

- 有监督（理想实际输出偏差，调整权值）
- 无监督（动态输入，寻找输入信息存在***模式规律***，调整权值）
- 灌输式（一次性权值）

#### 2、学习规则

- Hebb

  - 新权值 = 旧权值 + 学习率 * 输出 * 输入

- Delta

  - GD梯度下降，***误差平方和***
  - 新权值 = 旧权值 + 学习率 * 偏差 * 梯度* 输入

- LMS

  - ***误差平方和的均值***

  - Delta特例，学习速度快，精度高
  - 新权值 = 旧权值 + 学习率 * 偏差 * 输入

- 胜者为王

  - 响应最大的神经元才能调整权值

- Kohonen

  - 响应最大神经元，以及它的邻域可以调整权值

### 3.3 FNN和BPNN

#### 1、perceptron

- 单层计算单元，最简单的perceptron
- 学习
  - ***LMS***调整权值
  - 迭代方法
    - 循环次数控制
    - 分阶段迭代次数控制
    - 精度控制
    - 综合控制

#### 2、MLP

- 输入，隐含，输出

- 解决“异或”问题

#### 3、BPNN

- 要求：***激活函数可微***

- 迭代

  - 调整 ***输出层*** 和 ***隐含层***  权值
  - 新权值 = 旧权值 + 学习率 * 局部梯度* 上一层输出

- 优点：学习自主、可逼近任意非线性函数

- 缺点：算法***非全局收敛***、收敛速度慢、学习率选择、网络设计

  

*****

## 4. CNN

### 4.1 CNN

- 局部连接，权值共享

- 卷积后的尺寸
  - ![image-20230614153717880](C:\Users\xn666\AppData\Roaming\Typora\typora-user-images\image-20230614153717880.png)

- Pooling

  - 特征值筛选，提取和 ***卷积核*** 最像的部分 

  - 作用：降维，提速

  - 分类：最大池化，平均池化

  - 池化后大小

    <img src="C:\Users\xn666\AppData\Roaming\Typora\typora-user-images\image-20230614153641054.png" alt="image-20230614153641054" style="zoom:50%;" />

- 多通道卷积
  - 卷积核通道数 = 输入图片通道数
  - 卷积核个数 = 输出通道数

### 4.2 深度CNN

- 深度问题：过拟合，难收敛

- 数据集：训练、验证（非必需）、测试

- k折交叉验证
  - 将数据集分为训练集和测试集，将测试集放在一边 
  - 将训练集分为 k 份 
  - 每次使用 k 份中的 1 份作为验证集，其他全部作为训练集。 
  - 通过 k 次训练后，我们得到了 k 个不同的模型。 
  - 评估 k 个模型的效果，从中 ***挑选效果最好的超参数***
  - 使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终模型

- 维度灾难
  - 维度增加，分类器性能提高，维度过大时，性能下降
  - 原因：学习了太多特征导致***过拟合***
  - 解决：交叉验证，降维
- PCA降维
  - 核心：只保留含 ***绝大部分方差*** 的维度特征，忽略方差几乎为0的维度特征

- 超参数
  - 含义：人工设置的参数
  - 学习率，迭代次数，激活函数，batch-size，optimizer
- 初始化
  - 预训练初始化
  - 随机初始化
    -  依据概率分布随机初始化参数

- 归一化
  - 局部响应归一化（LRN）
    - 兴奋的神经细胞***抑制***周围神经细胞
    - 作用：局部对比度增强，使局部特征在下一层表达
  - 批标准化（BN）
    - 使一个batch的数据，满足***均值为0，方差为1***
    - 作用：使数据更加符合真实数据的分布，保证模型非线性表达能力
  - 层归一化
    - 单个训练数据对 ***某一层所有神经元*** 归一化
- 模型评估
  - 准确率
  - 召回率
    - TP / (TP + FN)
  - 精确率
    - 
      TP / (TP + FP)
  - F1-score
    - 同时考虑召回率和精确率，使二者同时达到最高

- 神经网络可视化
  - 反卷积法，用图片特征反向找各层参数，再找到参数对应图片区域
  - 1层关注***简单线条***；2层***简单形状***；3层***局部特征***；之后***全局特征***



